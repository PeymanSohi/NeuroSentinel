# üß† NeuroSentinel  
### Powered by AI, LLMs, Federated Learning, Threat Intelligence, and Forensics

---

## üîç Overview

This project is a **next-generation cybersecurity platform** designed to provide **autonomous, intelligent, and distributed defense** across multiple systems and networks. Combining the power of **machine learning**, **large language models (LLMs)**, **federated learning**, **threat intelligence APIs**, and **automated response mechanisms**, the platform detects, analyzes, and reacts to threats in real-time ‚Äî without human intervention.

Unlike traditional, centralized security solutions, this system empowers each node to monitor itself, learn local behavior, detect anomalies, and participate in a collaborative learning ecosystem ‚Äî all while preserving user privacy through **differential privacy**.

---

## üîë Key Features

- **Local Behavioral Anomaly Detection** using ML (AutoEncoders, Isolation Forest, etc.)
- **Federated Learning Engine** for collaborative model training across distributed nodes
- **Differential Privacy** to protect sensitive data while aggregating models
- **LLM-Powered Log Analysis** using local language models (LLaMA/Mistral) for natural language summarization of system events and security incidents
- **Autonomous Threat Response** (block malicious IPs, isolate processes, lock accounts, etc.)
- **Threat Intelligence Integration** with APIs like VirusTotal, AbuseIPDB, and OTX for enrichment
- **Real-Time Forensic Snapshot** creation after threat detection
- **Web-Based Dashboard** (React/Vue) for monitoring agents, alerts, and analysis results
- **DevOps-Ready** with full Docker support, Prometheus/Grafana observability, and CI/CD pipelines

---

## üöÄ Quick Start

### Prerequisites

- **Docker & Docker Compose**: Version 20.10+ and 2.0+
- **Git**: For cloning the repository
- **8GB+ RAM**: Recommended for running all services
- **10GB+ Disk Space**: For containers, models, and data

### Installation & Setup

1. **Clone the repository**
   ```bash
   git clone https://github.com/yourusername/NeuroSentinel.git
   cd NeuroSentinel
   ```

2. **Build all containers**
   ```bash
   docker-compose build
   ```

3. **Start core infrastructure**
   ```bash
   docker-compose up -d postgres redis prometheus
   ```

4. **Initialize the database**
   ```bash
   make db-init
   ```

5. **Start all services**
   ```bash
   docker-compose up -d
   ```

6. **Generate sample data and train models**
   ```bash
   make generate-sample-data
   make train-isolation-forest
   make train-autoencoder
   ```

### üéØ Running the Project

#### Start All Services
```bash
# Start everything
docker-compose up -d

# Check status
docker-compose ps

# View logs
docker-compose logs -f
```

#### Access Services

| Service | URL | Description |
|---------|-----|-------------|
| **Dashboard** | http://localhost:5173 | React frontend |
| **API Server** | http://localhost:8000 | FastAPI backend |
| **ML Core API** | http://localhost:9000 | ML model serving |
| **Prometheus** | http://localhost:9090 | Metrics monitoring |
| **PostgreSQL** | localhost:5432 | Database |
| **Redis** | localhost:6379 | Cache/Queue |

#### API Endpoints

```bash
# Health check
curl http://localhost:8000/health

# Get all events
curl http://localhost:8000/events

# Get all agents
curl http://localhost:8000/agents

# ML prediction
curl -X POST http://localhost:9000/predict \
  -H "Content-Type: application/json" \
  -d '{"data": {...}}'
```

#### Training ML Models

```bash
# Train Isolation Forest
make train-isolation-forest

# Train AutoEncoder
make train-autoencoder

# Quick training with minimal data
make quick-train

# Run tests
make test
```

#### Database Management

```bash
# Initialize database
make db-init

# Check database status
make db-check

# View database stats
make db-stats

# Reset database (DESTRUCTIVE)
make db-reset
```

#### Development Commands

```bash
# View service status
make status

# View recent logs
make logs

# Clean up temporary files
make clean

# Run tests locally
make test-local
```

### üìä Monitoring & Observability

#### Check System Health
```bash
# All services status
docker-compose ps

# Service health
curl http://localhost:8000/health | jq

# Database connectivity
make db-check

# ML API health
curl http://localhost:9000/health
```

#### View Logs
```bash
# All services
docker-compose logs -f

# Specific service
docker-compose logs -f server
docker-compose logs -f agent
docker-compose logs -f ml_core

# Recent training logs
make logs
```

#### Metrics & Monitoring
- **Prometheus**: http://localhost:9090
- **Grafana**: Available via Prometheus data source
- **Application Metrics**: Available via `/metrics` endpoints

### üîß Configuration

#### Environment Variables

Create `.env` file for custom configuration:

```bash
# Database
POSTGRES_DB=neurosentinel
POSTGRES_USER=neurosentinel
POSTGRES_PASSWORD=your_password

# Redis
REDIS_URL=redis://redis:6379

# Server
SERVER_HOST=0.0.0.0
SERVER_PORT=8000

# Agent
AGENT_ID=agent-001
AGENT_SERVER_URL=http://server:8000
AGENT_COLLECTION_INTERVAL=30

# ML Core
ML_CORE_HOST=0.0.0.0
ML_CORE_PORT=9000
```

#### Model Configuration

Edit config files in `ml_core/data/configs/`:

```json
{
  "model_type": "autoencoder",
  "model_params": {
    "hidden_dims": [64, 32, 16],
    "dropout_rate": 0.2,
    "activation": "relu"
  },
  "training": {
    "epochs": 50,
    "batch_size": 32
  }
}
```

### üß™ Testing

#### Run All Tests
```bash
# ML core tests
make test

# Local tests (requires venv)
make test-local

# Quick training test
make quick-train
```

#### Manual Testing

```bash
# Test agent data collection
docker-compose logs agent

# Test server API
curl http://localhost:8000/health

# Test ML predictions
curl -X POST http://localhost:9000/predict \
  -H "Content-Type: application/json" \
  -d '{"data": {"cpu_percent": 85, "memory_percent": 90}}'

# Test WebSocket connection
wscat -c ws://localhost:8000/ws
```

### üö® Troubleshooting

#### Common Issues

**1. Database Connection Errors**
```bash
# Reinitialize database
make db-init

# Check database status
make db-check
```

**2. Container Build Failures**
```bash
# Clean rebuild
docker-compose build --no-cache

# Remove all containers and volumes
docker-compose down -v
docker-compose up -d
```

**3. ML Training Failures**
```bash
# Check config files
ls -la ml_core/data/configs/

# Regenerate sample data
make generate-sample-data

# Clean and retrain
make clean
make train-isolation-forest
```

**4. Port Conflicts**
```bash
# Check what's using ports
lsof -i :8000
lsof -i :9000
lsof -i :5173

# Stop conflicting services
sudo systemctl stop conflicting-service
```

#### Log Analysis

```bash
# Check for errors
docker-compose logs | grep -i error

# Check for warnings
docker-compose logs | grep -i warn

# Follow specific service
docker-compose logs -f server | grep -i error
```

### üßπ Cleanup

#### Stop All Services
```bash
# Stop and remove containers
docker-compose down

# Stop and remove containers + volumes
docker-compose down -v

# Stop and remove containers + volumes + images
docker-compose down -v --rmi all
```

#### Clean Development Environment
```bash
# Clean temporary files
make clean

# Remove all containers
docker system prune -a

# Remove volumes
docker volume prune
```

---

## üß± Architecture Overview

```
+----------------+        +--------------------+        +-----------------+
|   Agent Node   | <----> | Central Intelligence| <----> |  Threat APIs    |
|  (Python App)  |        |   (FastAPI Server)  |        |  (VirusTotal‚Ä¶)  |
+----------------+        +--------------------+        +-----------------+
       |                            |                            |
       |     Federated Learning     |                            |
       |--------------------------->|                            |
       |                            |                            |
+------+----------------------------+----------------------------+
|              ML + LLM Core (Analysis Engine)                  |
|  - Autoencoder, IsolationForest, Opacus for DP                |
|  - LLaMA/Mistral for log summarization and detection          |
+---------------------------------------------------------------+
```

---

## üìÇ Components

| Module              | Description |
|---------------------|-------------|
| **Agent Node**      | Collects logs, monitors behavior, runs local ML models, performs automated actions, and takes forensic snapshots. |
| **FastAPI Backend** | Central server to manage agents, collect alerts, aggregate models, and interact with the dashboard. |
| **ML Engine**       | Trains anomaly detection models locally and aggregates them using Federated Learning with DP. |
| **LLM Engine**      | Parses and summarizes system logs using embedded language models to extract threats in plain English. |
| **Threat Intel**    | Queries VirusTotal, AbuseIPDB, and Shodan to enrich IP/domain/file analysis. |
| **Forensic Module** | Captures system state snapshots (RAM, open connections, process tree, etc.) for post-incident investigation. |
| **Dashboard**       | Web UI for visualizing node health, alerts, threat intelligence, model performance, and policies. |

---

## üõ†Ô∏è Technologies Used

- **Backend**: FastAPI, PostgreSQL, Redis
- **Frontend**: React.js or Vue.js, WebSockets
- **Machine Learning**: Scikit-learn, PyTorch, Opacus (DP)
- **LLM Integration**: LLaMA, Mistral, llama.cpp or Ollama
- **Security & Forensics**: psutil, scapy, watchdog, gcore, volatility
- **DevOps**: Docker, Docker Compose, Prometheus, Grafana, GitHub Actions

---

## üîÑ Comparison with Industry Tools

| Feature                                       | This Project ‚úÖ                              | Industry Tools (Darktrace, Wazuh, etc.) ‚ùå |
|----------------------------------------------|----------------------------------------------|--------------------------------------------|
| Distributed Autonomous Agents                | ‚úÖ Each node acts independently               | ‚ùå Centralized detection only               |
| Federated Learning                           | ‚úÖ Collaborative model training               | ‚ùå Not supported                            |
| Differential Privacy                         | ‚úÖ Protects sensitive data in training        | ‚ùå Not implemented                          |
| LLM-Based Log Summarization (e.g. LLaMA)     | ‚úÖ Embedded language model for log analysis   | üî∂ Rare (experimental in research only)     |
| Forensic Snapshot Engine                     | ‚úÖ Real-time memory/process dump              | ‚ùå Requires manual or external tools        |
| Open Source + Modular Architecture           | ‚úÖ Fully modular & extensible                 | ‚ùå Mostly closed-source or limited modules  |
| Threat Intel Enrichment with APIs            | ‚úÖ Integrated with public APIs                | ‚úÖ Available but often commercial           |
| DevOps-Friendly (Docker, CI/CD, Monitoring)  | ‚úÖ Full stack ready for deployment            | ‚ùå Often heavy or proprietary stack         |

---

## üöß Development Roadmap

### Phase 1 ‚Äì MVP
- [x] Basic agent for monitoring logs and files
- [x] FastAPI backend with alert ingestion and REST API
- [x] Basic dashboard UI
- [x] ML-based local anomaly detection
- [x] Database integration and persistence

### Phase 2 ‚Äì Core Intelligence
- [ ] Federated model sharing with DP
- [ ] Snapshot module for forensic capture
- [ ] Enhanced threat detection algorithms

### Phase 3 ‚Äì LLM & Threat API Integration
- [ ] LLM-powered log summarization
- [ ] VirusTotal and AbuseIPDB enrichment
- [ ] AI-generated threat reports in dashboard

### Phase 4 ‚Äì Privacy and Scalability
- [ ] Differential Privacy with Opacus
- [ ] Role-based access control
- [ ] Multi-node scalability with Kubernetes (optional)

---

## üìú License

This project is released under the MIT License. Contributions are welcome.

---

## üôã About the Author

This project was designed and developed by PeymanSohi, a DevOps & Python Engineer passionate about AI, cybersecurity, and building resilient distributed systems.

> *"Security is not just a feature ‚Äî it's a self-adaptive, intelligent organism in the modern cloud era."*


---

## üìù License

This project is licensed under the **Apache License 2.0**.  
See the [LICENSE](LICENSE) file for full details.

- ‚úÖ Free for commercial use  
- ‚úÖ Open to contributions and forks  
- ‚úÖ Includes patent grant protection  
- ‚úÖ Requires proper attribution

> By using this project, you agree not to use it for malicious or unethical purposes.


---

## üìù License

This project is licensed under the **Apache License 2.0**.  
See the [LICENSE](LICENSE) file for full license text.

## Project Overview
A smart, distributed cyber defense platform that learns system behaviors, detects and predicts threats, and responds autonomously when needed. It uses collaborative learning, large language models (LLMs), forensic analysis, and threat intelligence APIs to enhance its defense power.

## Directory Structure

- `agent/` ‚Äî Distributed agent node (collects, monitors, reports)
- `server/` ‚Äî Central FastAPI server (API, aggregation, orchestration)
- `ml_core/` ‚Äî ML engine (anomaly detection, federated learning)
- `llm_core/` ‚Äî LLM-based log analysis, summarization, reporting
- `forensics/` ‚Äî Forensic snapshot and analysis tools
- `threat_api/` ‚Äî Threat intelligence API integrations
- `dashboard/` ‚Äî Frontend dashboard (React/Vite)
- `shared/` ‚Äî Shared code (schemas, utils, config)

See module READMEs for more details.

# NeuroSentinel - Autonomous Distributed Cyber Defense Platform

A comprehensive, ML-powered cyber defense platform that provides real-time threat detection, anomaly analysis, and automated response capabilities.

## üöÄ Features

- **Advanced System Monitoring**: Comprehensive data collection from system, process, network, file, user, and security tools
- **ML-Powered Anomaly Detection**: Local machine learning models for real-time threat detection
- **Distributed Architecture**: Scalable agent-server architecture with containerized deployment
- **Real-time Processing**: WebSocket and REST API support for live data streaming
- **Threat Intelligence**: Integration with external threat feeds and indicators
- **Automated Response**: Configurable response actions based on detected threats

## üèóÔ∏è Architecture

```
NeuroSentinel/
‚îú‚îÄ‚îÄ agent/                 # Lightweight monitoring agent
‚îÇ   ‚îú‚îÄ‚îÄ collectors/        # Data collection modules
‚îÇ   ‚îú‚îÄ‚îÄ agent.py          # Main agent daemon
‚îÇ   ‚îî‚îÄ‚îÄ Dockerfile        # Agent container
‚îú‚îÄ‚îÄ server/               # Central server (FastAPI)
‚îÇ   ‚îú‚îÄ‚îÄ main.py          # API server
‚îÇ   ‚îî‚îÄ‚îÄ Dockerfile       # Server container
‚îú‚îÄ‚îÄ ml_core/             # Machine learning module
‚îÇ   ‚îú‚îÄ‚îÄ detectors/       # Anomaly detection algorithms
‚îÇ   ‚îú‚îÄ‚îÄ models/          # Neural network models
‚îÇ   ‚îú‚îÄ‚îÄ preprocessing/   # Data preprocessing
‚îÇ   ‚îú‚îÄ‚îÄ utils/           # ML utilities
‚îÇ   ‚îî‚îÄ‚îÄ train_models.py  # Training script
‚îú‚îÄ‚îÄ dashboard/           # React frontend
‚îú‚îÄ‚îÄ data/               # Training and validation data
‚îú‚îÄ‚îÄ models/             # Trained model artifacts
‚îî‚îÄ‚îÄ docker-compose.yml  # Orchestration
```

## üõ†Ô∏è Quick Start

### Prerequisites

- **Docker & Docker Compose**: Version 20.10+ and 2.0+
- **Git**: For cloning the repository
- **8GB+ RAM**: Recommended for running all services
- **10GB+ Disk Space**: For containers, models, and data

### Installation & Setup

1. **Clone the repository**
   ```bash
   git clone https://github.com/peymansohi/NeuroSentinel.git
   cd NeuroSentinel
   ```

2. **Build all containers**
   ```bash
   docker-compose build
   ```

3. **Start core infrastructure**
   ```bash
   docker-compose up -d postgres redis prometheus
   ```

4. **Initialize the database**
   ```bash
   make db-init
   ```

5. **Start all services**
   ```bash
   docker-compose up -d
   ```

6. **Generate sample data and train models**
   ```bash
   make generate-sample-data
   make train-isolation-forest
   make train-autoencoder
   ```

### üéØ Running the Project

#### Start All Services
```bash
# Start everything
docker-compose up -d

# Check status
docker-compose ps

# View logs
docker-compose logs -f
```

#### Access Services

| Service | URL | Description |
|---------|-----|-------------|
| **Dashboard** | http://localhost:5173 | React frontend |
| **API Server** | http://localhost:8000 | FastAPI backend |
| **ML Core API** | http://localhost:9000 | ML model serving |
| **Prometheus** | http://localhost:9090 | Metrics monitoring |
| **PostgreSQL** | localhost:5432 | Database |
| **Redis** | localhost:6379 | Cache/Queue |

#### API Endpoints

```bash
# Health check
curl http://localhost:8000/health

# Get all events
curl http://localhost:8000/events

# Get all agents
curl http://localhost:8000/agents

# ML prediction
curl -X POST http://localhost:9000/predict \
  -H "Content-Type: application/json" \
  -d '{"data": {...}}'
```

#### Training ML Models

```bash
# Train Isolation Forest
make train-isolation-forest

# Train AutoEncoder
make train-autoencoder

# Quick training with minimal data
make quick-train

# Run tests
make test
```

#### Database Management

```bash
# Initialize database
make db-init

# Check database status
make db-check

# View database stats
make db-stats

# Reset database (DESTRUCTIVE)
make db-reset
```

#### Development Commands

```bash
# View service status
make status

# View recent logs
make logs

# Clean up temporary files
make clean

# Run tests locally
make test-local
```

### üìä Monitoring & Observability

#### Check System Health
```bash
# All services status
docker-compose ps

# Service health
curl http://localhost:8000/health | jq

# Database connectivity
make db-check

# ML API health
curl http://localhost:9000/health
```

#### View Logs
```bash
# All services
docker-compose logs -f

# Specific service
docker-compose logs -f server
docker-compose logs -f agent
docker-compose logs -f ml_core

# Recent training logs
make logs
```

#### Metrics & Monitoring
- **Prometheus**: http://localhost:9090
- **Grafana**: Available via Prometheus data source
- **Application Metrics**: Available via `/metrics` endpoints

### üîß Configuration

#### Environment Variables

Create `.env` file for custom configuration:

```bash
# Database
POSTGRES_DB=neurosentinel
POSTGRES_USER=neurosentinel
POSTGRES_PASSWORD=your_password

# Redis
REDIS_URL=redis://redis:6379

# Server
SERVER_HOST=0.0.0.0
SERVER_PORT=8000

# Agent
AGENT_ID=agent-001
AGENT_SERVER_URL=http://server:8000
AGENT_COLLECTION_INTERVAL=30

# ML Core
ML_CORE_HOST=0.0.0.0
ML_CORE_PORT=9000
```

#### Model Configuration

Edit config files in `ml_core/data/configs/`:

```json
{
  "model_type": "autoencoder",
  "model_params": {
    "hidden_dims": [64, 32, 16],
    "dropout_rate": 0.2,
    "activation": "relu"
  },
  "training": {
    "epochs": 50,
    "batch_size": 32
  }
}
```

### üß™ Testing

#### Run All Tests
```bash
# ML core tests
make test

# Local tests (requires venv)
make test-local

# Quick training test
make quick-train
```

#### Manual Testing

```bash
# Test agent data collection
docker-compose logs agent

# Test server API
curl http://localhost:8000/health

# Test ML predictions
curl -X POST http://localhost:9000/predict \
  -H "Content-Type: application/json" \
  -d '{"data": {"cpu_percent": 85, "memory_percent": 90}}'

# Test WebSocket connection
wscat -c ws://localhost:8000/ws
```

### üö® Troubleshooting

#### Common Issues

**1. Database Connection Errors**
```bash
# Reinitialize database
make db-init

# Check database status
make db-check
```

**2. Container Build Failures**
```bash
# Clean rebuild
docker-compose build --no-cache

# Remove all containers and volumes
docker-compose down -v
docker-compose up -d
```

**3. ML Training Failures**
```bash
# Check config files
ls -la ml_core/data/configs/

# Regenerate sample data
make generate-sample-data

# Clean and retrain
make clean
make train-isolation-forest
```

**4. Port Conflicts**
```bash
# Check what's using ports
lsof -i :8000
lsof -i :9000
lsof -i :5173

# Stop conflicting services
sudo systemctl stop conflicting-service
```

#### Log Analysis

```bash
# Check for errors
docker-compose logs | grep -i error

# Check for warnings
docker-compose logs | grep -i warn

# Follow specific service
docker-compose logs -f server | grep -i error
```

### üßπ Cleanup

#### Stop All Services
```bash
# Stop and remove containers
docker-compose down

# Stop and remove containers + volumes
docker-compose down -v

# Stop and remove containers + volumes + images
docker-compose down -v --rmi all
```

#### Clean Development Environment
```bash
# Clean temporary files
make clean

# Remove all containers
docker system prune -a

# Remove volumes
docker volume prune
```

---

## üìú License

This project is licensed under the **Apache License 2.0**.  
See the [LICENSE](LICENSE) file for full details.

- ‚úÖ Free for commercial use  
- ‚úÖ Open to contributions and forks  
- ‚úÖ Includes patent grant protection  
- ‚úÖ Requires proper attribution

> By using this project, you agree not to use it for malicious or unethical purposes.

